{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class camera:\n",
    "    \"\"\" An class that contains all the data for a camera \"\"\"\n",
    "    def __init__(self, horizontal_fov: int, vertical_fov: int, resolution: tuple, location: tuple, direction: tuple, view_distance: tuple):\n",
    "        self.horizontal_fov = horizontal_fov\n",
    "        self.vertical_fov = vertical_fov\n",
    "        self.resolution = resolution\n",
    "        self.location = location\n",
    "        self.direction = direction\n",
    "        self.view_distance = view_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mesh3D:\n",
    "    \"\"\" An class that contains all the data for a mesh \"\"\"\n",
    "    def __init__(self, verticies: list, faces: list, center: tuple):\n",
    "        self.verticies = verticies\n",
    "        self.faces = faces\n",
    "        self.center = center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(pixels: list, image_name: str):\n",
    "    \"\"\"takes in a numpy array of tuples of rgb values and converts it into a image then it saves the image as a file and displays the image\"\"\"\n",
    "    pixels = list(zip(*pixels))[::-1]\n",
    "    array = np.array(pixels, dtype=np.uint8)\n",
    "    new_image = Image.fromarray(array)\n",
    "    display(new_image)\n",
    "    new_image.save(image_name + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_2dimage(dimensions: tuple, background_color: tuple) -> list:\n",
    "    ''' Creates a three dimensional numpy array of a certain size that dimension1 x dimension2 x 3 to represent the RGB value at each point'''\n",
    "    image = np.zeros((1000, 1000, 3), dtype=np.uint8)\n",
    "    image[:, :, 0] = background_color[0] \n",
    "    image[:, :, 1] = background_color[1] \n",
    "    image[:, :, 2] = background_color[2] \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_2d(point_1: np.ndarray, point_2: np.ndarray):\n",
    "    \"\"\" \n",
    "    Acts as a generator which yields the the cordinates of subsequent points on a line formed between two inputed points as tuples\n",
    "\n",
    "    SPECIAL INFORMATION\n",
    "    - Lines include both end points\n",
    "    -only one pixel per line in the direction which moves the most over time \n",
    "        - EX: (0,0) to (5,20) there would only every be one box per y value\n",
    "    \"\"\"\n",
    "\n",
    "    x1, y1 = point_1\n",
    "    x2, y2 = point_2\n",
    "\n",
    "    #preparation calculations (differences and direction)\n",
    "    difference_x = abs(x2 - x1)\n",
    "    difference_y = abs(y2 - y1)\n",
    "    if x2 > x1:\n",
    "        x_sign = 1\n",
    "    else:\n",
    "        x_sign = -1\n",
    "    if y2 > y1:\n",
    "        y_sign = 1\n",
    "    else:\n",
    "        y_sign = -1\n",
    "\n",
    "    if difference_x > difference_y: # senario when the x value changes more than y in the line\n",
    "        y_error = 2*difference_y - difference_x\n",
    "        yield (int(x1),int(y1))\n",
    "        while x1 != x2:\n",
    "            x1 += x_sign\n",
    "            if y_error >= 0:\n",
    "                y1 += y_sign\n",
    "                y_error -= 2 * difference_x\n",
    "            y_error += 2 * difference_y \n",
    "            yield (int(x1),int(y1))\n",
    "\n",
    "    else: # senarion when y changes more than x or both change the exact same amount\n",
    "        x_error = 2*difference_x - difference_y\n",
    "        yield (int(x1),int(y1))\n",
    "        while y1 != y2:\n",
    "            y1 += y_sign\n",
    "            if x_error >= 0:\n",
    "                x1 += x_sign\n",
    "                x_error -= 2 * difference_y\n",
    "            x_error += 2 * difference_x \n",
    "            yield (int(x1),int(y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_cords(center: np.ndarray, model_verticies: np.ndarray):\n",
    "    \"\"\"Will return location of a meshes verticies in global space from inputtings its center location and mesh information\"\"\"\n",
    "    transformation_matrix = np.array([[1,0,0,center[0]],\n",
    "                                      [0,1,0,center[1]],\n",
    "                                      [0,0,1,center[2]],\n",
    "                                      [0,0,0,1]])\n",
    "    return [np.dot(transformation_matrix,vertex) for vertex in model_verticies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorient_to_camera(self, cam: camera, global_verticies: np.ndarray):\n",
    "    \"\"\"reorients and rotates verticies to be aligned with the camera at (0,0) with the positive direction where the camera is looking\"\"\"\n",
    "    translation_matrix = np.array([[1,0,0,-cam.location[0]],\n",
    "                                    [0,1,0,-cam.location[1]],\n",
    "                                    [0,0,1,-cam.location[2]],\n",
    "                                    [0,0,0,1]])\n",
    "    x_rotation_matrix = np.array([[1,0,0,0],\n",
    "                                  [0,math.cos(math.radians(-cam.direction[0])),-math.sin(math.radians(-cam.direction[0])),0],\n",
    "                                  [0,math.sin(math.radians(-cam.direction[0])),math.cos(math.radians(-cam.direction[0])),0],\n",
    "                                  [0,0,0,1]])\n",
    "    y_rotation_matrix = np.array([[math.cos(math.radians(-cam.direction[1])),0,math.sin(math.radians(-cam.direction[1])),0],\n",
    "                                  [0,1,0,0],\n",
    "                                  [-math.sin(math.radians(-cam.direction[1])),0,math.cos(math.radians(-cam.direction[1])),0],\n",
    "                                  [0,0,0,1]])\n",
    "    z_rotation_matrix = np.array([[math.cos(math.radians(-cam.direction[2])),-math.sin(math.radians(-cam.direction[2])),0,0],\n",
    "                                  [math.sin(math.radians(-cam.direction[2])),math.cos(math.radians(-cam.direction[2])),0,0],\n",
    "                                  [0,0,1,0],\n",
    "                                  [0,0,0,1]])\n",
    "    return [np.dot(np.dot(np.dot(np.dot(point,translation_matrix),x_rotation_matrix),y_rotation_matrix),z_rotation_matrix) for point in global_verticies] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ POTENTIALLY REMOVE THIS IF CLIPPING IN THE RASTERIZATION FUNCTION WORKS WELL ENOUGH############\n",
    "def clipping(cam: camera, oriented_to_camera_verticies: np.ndarray, faces: np.ndarray):\n",
    "    ''' takes in verticies location in respect to the camera and runs through each face to determine if it is in the fov of the camera. If none of the face is in the camera it will get deleted'''\n",
    "    remaining_faces = []\n",
    "    for face in faces:\n",
    "        for point_idx in face:\n",
    "            point = oriented_to_camera_verticies[point_idx]\n",
    "            if cam.horizontal_fov >= abs(math.degrees(math.tan(point[0]/point[2]))) and cam.vertical_fov >= abs(math.degrees(math.tan(point[1]/point[2]))) and cam.view_distance[1] >= point[2] >= cam.view_distance[0]:\n",
    "                remaining_faces.append(face)\n",
    "                break\n",
    "    return remaining_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perspective_projection(cam: camera, oriented_to_camera_vertices: np.ndarray):\n",
    "\n",
    "    projection_matrix = np.array([\n",
    "        [cam.view_distance[0] / math.tan(math.radians(cam.horizontal_fov / 2)), 0, 0, 0],\n",
    "        [0, cam.view_distance[0] / math.tan(math.radians(cam.vertical_fov / 2)), 0, 0],\n",
    "        [0, 0, cam.view_distance[1] - cam.view_distance[0], -cam.view_distance[0] * cam.view_distance[0]],\n",
    "        [0, 0, 1, 0]])\n",
    "\n",
    "    points_in_2d = []\n",
    "    for vertex in oriented_to_camera_vertices:\n",
    "        homogeneous_point = np.dot(vertex, projection_matrix)\n",
    "        w_reciprocal = 1.0 / homogeneous_point[3]\n",
    "\n",
    "        # Avoid creating unnecessary NumPy array, use a temporary variable instead\n",
    "        projected_point = [homogeneous_point[0] * w_reciprocal, homogeneous_point[1] * w_reciprocal, homogeneous_point[3], 1]\n",
    "        points_in_2d.append(projected_point)\n",
    "\n",
    "    return points_in_2d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_culling(oriented_to_camera_verticies: np.ndarray, faces: np.ndarray):\n",
    "    ''' takes in faces and verticies and returns a list of faces excluding any faces that would be looking away from the camera and occluded by other faces in front of it'''\n",
    "    culled_faces = []\n",
    "    for face in faces:\n",
    "        ax, ay, az, _ = oriented_to_camera_verticies[face[0]]\n",
    "        bx, by, bz, _  = oriented_to_camera_verticies[face[1]]\n",
    "        cx, cy, cz, _  = oriented_to_camera_verticies[face[2]]\n",
    "        #relies on any mesh textextures to have their faces to have vectors cross product face out of the mesh\n",
    "        vector1 = np.array([bx-ax, by-ay, bz-az]) \n",
    "        vector2 = np.array([bx-cx, by-cy, bz-cz])\n",
    "        angle = np.cross(vector1, vector2)\n",
    "        if np.dot(angle, oriented_to_camera_verticies[face[1]][:2]) < 0:\n",
    "            culled_faces.append(face)\n",
    "    return culled_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def screen_space(cam: camera, verticies: np.ndarray):\n",
    "    ''' Takes in verticies after the perspective projection and adjusts them to the resolution of the screen '''\n",
    "    return np.array([[round((vertex[0]+1)*cam.resolution[0]/2),round((vertex[1]+1)*cam.resolution[1]/2),vertex[2],1] for vertex in verticies])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note to self use Cython to make the program run faster when I am done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
